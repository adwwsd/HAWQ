PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 8) {
    for (ax3, 0, 2) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*64) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*64) + (ax4*8)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_1"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 72) {
    for (ax3, 0, 2) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*64) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*64) + (ax4*8)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_2"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 32) {
    for (ax3, 0, 2) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*64) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*64) + (ax4*8)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_3"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 8) {
    for (ax3, 0, 8) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax4*32)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_4"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 16) {
    for (ax3, 0, 8) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax4*32)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_5"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 144) {
    for (ax3, 0, 4) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*128) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*128) + (ax4*16)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_6"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 64) {
    for (ax3, 0, 4) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*128) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*128) + (ax4*16)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_7"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 64) {
    for (ax3, 0, 8) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax4*32)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_8"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 16) {
    for (ax3, 0, 16) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax4*64)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_9"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 32) {
    for (ax3, 0, 16) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax4*64)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_10"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 288) {
    for (ax3, 0, 8) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax4*32)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_11"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 128) {
    for (ax3, 0, 8) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*256) + (ax4*32)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_12"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 128) {
    for (ax3, 0, 16) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax4*64)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_13"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 32) {
    for (ax3, 0, 32) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*1024) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*1024) + (ax4*128)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_14"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 64) {
    for (ax3, 0, 32) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*1024) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*1024) + (ax4*128)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_15"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 576) {
    for (ax3, 0, 16) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax4*64)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_16"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 256) {
    for (ax3, 0, 16) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*512) + (ax4*64)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_17"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 256) {
    for (ax3, 0, 32) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*1024) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*1024) + (ax4*128)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, T_layout_trans]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_layout_transform_18"} {
  parallel (ax0.ax1.fused.ax2.fused, 0, 64) {
    for (ax3, 0, 64) {
      for (ax4, 0, 8) {
        for (ax5.outer, 0, 2) {
          T_layout_trans[(x16(((((ax0.ax1.fused.ax2.fused*2048) + (ax3*32)) + (ax4*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))] = placeholder[(x16(((((ax0.ax1.fused.ax2.fused*2048) + (ax4*256)) + (ax3*4)) + (ax5.outer*2))) + (ramp(0, 1, 16)/x16(8)))]
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_multiply]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_dense_add_cast_subtract_cast_multiply"} {
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 2
  // attr [compute.local] storage_scope = "local"
  allocate compute.local[int32 * 20]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int8 * 2048]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int8 * 1280]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 50
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 16
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 2
  compute.local[0] = 0
  compute.local[10] = 0
  compute.local[1] = 0
  compute.local[11] = 0
  compute.local[2] = 0
  compute.local[12] = 0
  compute.local[3] = 0
  compute.local[13] = 0
  compute.local[4] = 0
  compute.local[14] = 0
  compute.local[5] = 0
  compute.local[15] = 0
  compute.local[6] = 0
  compute.local[16] = 0
  compute.local[7] = 0
  compute.local[17] = 0
  compute.local[8] = 0
  compute.local[18] = 0
  compute.local[9] = 0
  compute.local[19] = 0
  for (k.outer.outer, 0, 32) {
    unrolled (ax0.ax1.outer.fused.outer.outer, 0, 4) {
      // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 16
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 2
      placeholder.shared[ramp((((ax0.ax1.outer.fused.outer.outer*512) + (threadIdx.y*32)) + (threadIdx.x*16)), 1, 16)] = placeholder[ramp((((((blockIdx.y*65536) + (ax0.ax1.outer.fused.outer.outer*16384)) + (floordiv(((threadIdx.y*2) + threadIdx.x), 4)*2048)) + (k.outer.outer*64)) + (floormod(((threadIdx.y*2) + threadIdx.x), 4)*16)), 1, 16)]
    }
    unrolled (ax0.ax1.outer.fused.outer.outer, 0, 3) {
      // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 16
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 2
      if (((((ax0.ax1.outer.fused.outer.outer*32) + (threadIdx.y*2)) + threadIdx.x) < 80)) {
        if ((((ax0.ax1.outer.fused.outer.outer*16) + threadIdx.y) < 40)) {
          if (((((blockIdx.x*20) + (ax0.ax1.outer.fused.outer.outer*8)) + floordiv(((threadIdx.y*2) + threadIdx.x), 4)) < 1000)) {
            placeholder.shared[ramp((((ax0.ax1.outer.fused.outer.outer*512) + (threadIdx.y*32)) + (threadIdx.x*16)), 1, 16)] = placeholder[ramp((((((blockIdx.x*40960) + (ax0.ax1.outer.fused.outer.outer*16384)) + (floordiv(((threadIdx.y*2) + threadIdx.x), 4)*2048)) + (k.outer.outer*64)) + (floormod(((threadIdx.y*2) + threadIdx.x), 4)*16)), 1, 16)]
          }
        }
      }
    }
    unrolled (k.outer.inner, 0, 16) {
      compute.local[0] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp(((threadIdx.x*64) + (k.outer.inner*4)), 1, 4)], compute.local[0])
      compute.local[10] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp(((threadIdx.x*64) + (k.outer.inner*4)), 1, 4)], compute.local[10])
      compute.local[1] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 128), 1, 4)], compute.local[1])
      compute.local[11] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 128), 1, 4)], compute.local[11])
      compute.local[2] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 256), 1, 4)], compute.local[2])
      compute.local[12] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 256), 1, 4)], compute.local[12])
      compute.local[3] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 384), 1, 4)], compute.local[3])
      compute.local[13] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 384), 1, 4)], compute.local[13])
      compute.local[4] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 512), 1, 4)], compute.local[4])
      compute.local[14] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 512), 1, 4)], compute.local[14])
      compute.local[5] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 640), 1, 4)], compute.local[5])
      compute.local[15] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 640), 1, 4)], compute.local[15])
      compute.local[6] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 768), 1, 4)], compute.local[6])
      compute.local[16] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 768), 1, 4)], compute.local[16])
      compute.local[7] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 896), 1, 4)], compute.local[7])
      compute.local[17] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 896), 1, 4)], compute.local[17])
      compute.local[8] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 1024), 1, 4)], compute.local[8])
      compute.local[18] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 1024), 1, 4)], compute.local[18])
      compute.local[9] = __dp4a(placeholder.shared[ramp(((threadIdx.y*64) + (k.outer.inner*4)), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 1152), 1, 4)], compute.local[9])
      compute.local[19] = __dp4a(placeholder.shared[ramp((((threadIdx.y*64) + (k.outer.inner*4)) + 1024), 1, 4)], placeholder.shared[ramp((((threadIdx.x*64) + (k.outer.inner*4)) + 1152), 1, 4)], compute.local[19])
    }
  }
  T_multiply[((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x)] = (float32((compute.local[0] + placeholder[((blockIdx.x*20) + threadIdx.x)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16000)] = (float32((compute.local[10] + placeholder[((blockIdx.x*20) + threadIdx.x)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 2)] = (float32((compute.local[1] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 2)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16002)] = (float32((compute.local[11] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 2)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 4)] = (float32((compute.local[2] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 4)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16004)] = (float32((compute.local[12] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 4)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 6)] = (float32((compute.local[3] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 6)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16006)] = (float32((compute.local[13] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 6)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 8)] = (float32((compute.local[4] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 8)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16008)] = (float32((compute.local[14] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 8)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 10)] = (float32((compute.local[5] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 10)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16010)] = (float32((compute.local[15] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 10)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 12)] = (float32((compute.local[6] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 12)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16012)] = (float32((compute.local[16] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 12)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 14)] = (float32((compute.local[7] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 14)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16014)] = (float32((compute.local[17] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 14)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16)] = (float32((compute.local[8] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 16)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16016)] = (float32((compute.local[18] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 16)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 18)] = (float32((compute.local[9] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 18)]))*74f)
  T_multiply[(((((blockIdx.y*32000) + (threadIdx.y*1000)) + (blockIdx.x*20)) + threadIdx.x) + 16018)] = (float32((compute.local[19] + placeholder[(((blockIdx.x*20) + threadIdx.x) + 18)]))*74f)
}


PrimFunc([placeholder, tensor]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_batch_flatten"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 128
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  tensor[((blockIdx.x*1024) + threadIdx.x)] = placeholder[((blockIdx.x*1024) + threadIdx.x)]
}


PrimFunc([placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_global_avg_pool2d_cast_cast_left_shift_multiply_add_right_shift_cast_cl_10830175937736834516_"} {
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 8
  // attr [tensor] storage_scope = "local"
  allocate tensor[int32 * 1]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.y, range(min=0, ext=8), threadIdx.y)] thread_extent = 8
  // attr [iter_var(threadIdx.x, range(min=0, ext=8), threadIdx.x)] thread_extent = 8
  tensor[0] = 0
  for (rv0, 0, 7) {
    for (rv1, 0, 7) {
      tensor[0] = (tensor[0] + placeholder[((((((blockIdx.y*802816) + (threadIdx.y*100352)) + (rv0*14336)) + (rv1*2048)) + (blockIdx.x*8)) + threadIdx.x)])
    }
  }
  T_cast[((((blockIdx.y*16384) + (threadIdx.y*2048)) + (blockIdx.x*8)) + threadIdx.x)] = int8(max(min(int32(shift_right(((shift_left(int64((tensor[0]/49)), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 127), -128))
}


PrimFunc([placeholder, T_transpose]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_transpose"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer, 0, 25) {
    if ((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*128) + floordiv(((blockIdx.x*1024) + threadIdx.x), 2048)) < 3136)) {
      if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528)) {
        T_transpose[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = placeholder[(((floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*128) + floordiv(((blockIdx.x*1024) + threadIdx.x), 2048)), 49)*131072) + (floordiv(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*128) + floordiv(((blockIdx.x*1024) + threadIdx.x), 2048)), 49)*2048)) + floormod(((blockIdx.x*1024) + threadIdx.x), 2048))]
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_cast_cast_multiply_add_right_shift_cast_add_clip_cast_n_16373524651668054328_"} {
  // attr [compute] storage_scope = "global"
  allocate compute[uint4 * 1605632]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 196
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner, 0, 8) {
    compute[(((floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32768)*4096) + (floormod(((blockIdx.x*2) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)), 8)*512)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)/8))] = placeholder[(((((floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32768)*4096) + (floormod(((blockIdx.x*2) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)), 8)*512)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 256), 32)*64)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096), 256)*4)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32)/8))]
  }
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 49
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 32768]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 4096]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 16384]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 16384]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 32
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  for (n.c.init, 0, 2) {
    for (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  for (ax2.inner.inner, 0, 2) {
    for (ax3, 0, 16) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      compute.shared[((((threadIdx.y*1024) + (ax2.inner.inner*512)) + (ax3*32)) + threadIdx.x)] = compute[(((((blockIdx.z*4096) + (threadIdx.y*1024)) + (ax2.inner.inner*512)) + (ax3*32)) + threadIdx.x)]
    }
  }
  for (ic.outer, 0, 2) {
    for (ax2, 0, 2) {
      for (ax3, 0, 8) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((((threadIdx.y*8192) + (ax2*4096)) + (ic.outer*2048)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    for (ax2, 0, 8) {
      for (ax3.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.inner, 0, 8) {
          placeholder.shared[((((ax2*256) + (threadIdx.y*64)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*4096) + (ax2*512)) + (ic.outer*256)) + (threadIdx.y*64)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    for (ax2, 0, 8) {
      for (ax3, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    for (ic.inner, 0, 8) {
      for (n.c, 0, 2) {
        for (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  for (n.inner, 0, 2) {
    for (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*1024) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  for (ax2.outer.inner, 0, 2) {
    for (ax3.outer.inner, 0, 8) {
      for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_relu[((((((((blockIdx.z*131072) + (threadIdx.y*32768)) + (ax2.outer.inner*16384)) + (ax2.inner.ax3.inner.fused.outer*8192)) + (floordiv(threadIdx.x, 8)*2048)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((compute.shared[(((((threadIdx.y*1024) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + int32(shift_right(((int64(placeholder[((((((((blockIdx.z*131072) + (threadIdx.y*32768)) + (ax2.outer.inner*16384)) + (ax2.inner.ax3.inner.fused.outer*8192)) + (floordiv(threadIdx.x, 8)*2048)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])*(int64)1886303204) + (int64)1073741824), (int64)31))), 2147483647), 0)
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188_"} {
  // attr [compute] storage_scope = "global"
  allocate compute[uint4 * 2654208]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer, 0, 2) {
    for (h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner, 0, 8) {
      if ((((((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner) < 2654208)) {
        if (((((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 331776)) {
          compute[((((floordiv(((((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 294912)*36864) + (floormod(((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32768)), 9)*4096)) + (floormod(((blockIdx.x*2) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)), 8)*512)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)/8))] = placeholder[((((((floordiv(((((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 294912)*36864) + (floormod(((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32768)), 9)*4096)) + (floormod(((blockIdx.x*2) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)), 8)*512)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 256), 32)*64)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096), 256)*4)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32)/8))]
        }
      }
    }
  }
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 49
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 8192]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 4096]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 8
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 4) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*4) + o.c.init), 0f)
    }
  }
  for (kh, 0, 3) {
    for (ic.outer, 0, 4) {
      unrolled (kw, 0, 3) {
        // attr [compute.shared] double_buffer_scope = 1
        unrolled (ax2.inner.inner, 0, 4) {
          unrolled (ax3, 0, 4) {
            // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
            compute.shared[((((threadIdx.z*512) + (ax2.inner.inner*128)) + (ax3*32)) + threadIdx.x)] = compute[(((((((((floordiv(blockIdx.z, 7)*36864) + (kh*36864)) + (kw*4096)) + (floormod(blockIdx.z, 7)*4096)) + (threadIdx.z*2048)) + (ax2.inner.inner*512)) + (ic.outer*128)) + (ax3*32)) + threadIdx.x)]
          }
        }
        unrolled (ax2, 0, 8) {
          unrolled (ax3, 0, 4) {
            tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*1024) + (ax3*256)), 256, 1), 32, "row_major")
          }
        }
        // attr [placeholder.shared] double_buffer_scope = 1
        unrolled (ax2, 0, 8) {
          unrolled (ax3.inner.inner, 0, 2) {
            // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
            compute.shared[((((ax2*128) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((((kh*98304) + (kw*32768)) + (blockIdx.y*4096)) + (ax2*512)) + (ic.outer*128)) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)]
          }
        }
        unrolled (ax2, 0, 4) {
          unrolled (ax3, 0, 4) {
            tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.z*4096) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
          }
        }
        unrolled (ic.inner, 0, 4) {
          unrolled (n.c, 0, 8) {
            unrolled (o.c, 0, 4) {
              tvm_mma_sync(Conv.wmma.accumulator, ((n.c*4) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*4) + o.c))
            }
          }
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 4) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*4) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((n.inner*512) + (threadIdx.z*256)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 4) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*4096) + (ax2.outer.inner*512)) + (ax2.inner.ax3.inner.fused.outer*256)) + (floordiv(threadIdx.x, 8)*64)) + (blockIdx.y*8)) + (threadIdx.z*4)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[(((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_pad]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_pad"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 2) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 2654208)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 331776)) {
          T_pad[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 294912)*36864) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 9)*4096)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*64)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)/8))] = tvm_if_then_else(((((294912 <= ((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner)) && (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 2359296)) && (1 <= floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 9))) && (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 9) < 8)), placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 294912)*28672) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 9)*4096)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*64)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)/8)) - 32768)], 0)
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__1"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 49
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 16384]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 16384]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 8
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (n.c.init, 0, 4) {
    unrolled (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  for (ic.outer, 0, 8) {
    unrolled (ax2.inner.inner, 0, 4) {
      unrolled (ax3, 0, 8) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
          compute.shared[((((threadIdx.y*1024) + (ax2.inner.inner*256)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*16384) + (threadIdx.y*8192)) + (ax2.inner.inner*2048)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*256)) + (ic.outer*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
        }
      }
    }
    unrolled (ax2, 0, 4) {
      unrolled (ax3, 0, 8) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*8192) + (ax2*2048)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    unrolled (ax2, 0, 8) {
      unrolled (ax3.inner.inner, 0, 4) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
          compute.shared[((((ax2*256) + (threadIdx.y*128)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*16384) + (ax2*2048)) + (ic.outer*256)) + (threadIdx.y*128)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 8) {
      unrolled (n.c, 0, 4) {
        unrolled (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 4) {
    unrolled (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((threadIdx.y*2048) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (ax2.outer.inner, 0, 4) {
    unrolled (ax3.outer.inner, 0, 8) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*4096) + (threadIdx.y*2048)) + (ax2.outer.inner*512)) + (ax2.inner.ax3.inner.fused.outer*256)) + (floordiv(threadIdx.x, 8)*64)) + (blockIdx.y*8)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((blockIdx.y*64) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_cast_cast_left_shift_multiply_add_right_shift_cast_clip_cast"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 4) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 6422528)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 802816)) {
          T_cast[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*114688) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*16384)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*256)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)/8))] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8))]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 1)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 2)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 3)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 4)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 5)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 6)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*16) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 131072)), 7)*131072)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048)), 64)*2048)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 2048), 8)*8)) + 7)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15)))
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_add_clip_cast_nn_relu"} {
  // attr [compute] storage_scope = "global"
  allocate compute[uint4 * 1605632]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 196
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner, 0, 8) {
    compute[(((floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32768)*4096) + (floormod(((blockIdx.x*2) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)), 8)*512)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)/8))] = placeholder[(((((floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32768)*4096) + (floormod(((blockIdx.x*2) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096)), 8)*512)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 256), 32)*64)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 4096), 256)*4)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32)/8))]
  }
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 49
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 32768]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 4096]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 16384]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 16384]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 32
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  for (n.c.init, 0, 2) {
    for (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  for (ax2.inner.inner, 0, 2) {
    for (ax3, 0, 16) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      compute.shared[((((threadIdx.y*1024) + (ax2.inner.inner*512)) + (ax3*32)) + threadIdx.x)] = compute[(((((blockIdx.z*4096) + (threadIdx.y*1024)) + (ax2.inner.inner*512)) + (ax3*32)) + threadIdx.x)]
    }
  }
  for (ic.outer, 0, 2) {
    for (ax2, 0, 2) {
      for (ax3, 0, 8) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((((threadIdx.y*8192) + (ax2*4096)) + (ic.outer*2048)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    for (ax2, 0, 8) {
      for (ax3.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.inner, 0, 8) {
          placeholder.shared[((((ax2*256) + (threadIdx.y*64)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*4096) + (ax2*512)) + (ic.outer*256)) + (threadIdx.y*64)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    for (ax2, 0, 8) {
      for (ax3, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    for (ic.inner, 0, 8) {
      for (n.c, 0, 2) {
        for (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  for (n.inner, 0, 2) {
    for (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*1024) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  for (ax2.outer.inner, 0, 2) {
    for (ax3.outer.inner, 0, 8) {
      for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_relu[((((((((blockIdx.z*131072) + (threadIdx.y*32768)) + (ax2.outer.inner*16384)) + (ax2.inner.ax3.inner.fused.outer*8192)) + (floordiv(threadIdx.x, 8)*2048)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((compute.shared[(((((threadIdx.y*1024) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + placeholder[((((((((blockIdx.z*131072) + (threadIdx.y*32768)) + (ax2.outer.inner*16384)) + (ax2.inner.ax3.inner.fused.outer*8192)) + (floordiv(threadIdx.x, 8)*2048)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]), 2147483647), 0)
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__2"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 49
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 32768]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 4096]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 16384]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 8192]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 2
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (n.c.init, 0, 4) {
    unrolled (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax2.inner.inner, 0, 2) {
    unrolled (ax3, 0, 32) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[((((threadIdx.z*2048) + (ax2.inner.inner*1024)) + (ax3*32)) + threadIdx.x)] = placeholder[((((((((floordiv(blockIdx.z, 7)*229376) + (floormod(blockIdx.z, 7)*16384)) + (blockIdx.x*4096)) + (threadIdx.z*2048)) + (ax2.inner.inner*1024)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*128)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  for (ic.outer, 0, 8) {
    unrolled (ax2, 0, 4) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((ax2*8192) + (ic.outer*1024)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    unrolled (ax2, 0, 16) {
      unrolled (ax3.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        placeholder.shared[((((ax2*128) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*16384) + (ax2*1024)) + (ic.outer*128)) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)]
      }
    }
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.z*8192) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 4) {
      unrolled (n.c, 0, 4) {
        unrolled (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 4) {
    unrolled (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), compute.shared, (((n.inner*1024) + (threadIdx.z*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (ax2.outer.inner, 0, 4) {
    unrolled (ax3.outer.inner, 0, 8) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[((((((((blockIdx.z*4096) + (blockIdx.x*2048)) + (ax2.outer.inner*512)) + (ax2.inner.ax3.inner.fused.outer*256)) + (floordiv(threadIdx.x, 8)*64)) + (blockIdx.y*16)) + (threadIdx.z*8)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[(((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[(((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_cast_cast_left_shift_multiply_add_right_shift_cast_clip_cast_1"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 7) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 12845056)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 1605632)) {
          T_cast[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*114688) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*8192)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*128)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)/8))] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8))]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 1)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 2)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 3)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 4)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 5)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 6)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*32) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 65536)), 14)*65536)) + (floormod(((blockIdx.x*8) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024)), 64)*1024)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 1024), 8)*8)) + 7)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15)))
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_cast_cast_multiply_add_right_shift_cast_add_clip_cast_n_16373524651668054328__1"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 196
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 16384]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 16
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 2) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*2) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax2.inner.inner, 0, 2) {
    unrolled (ax3, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[((((threadIdx.z*512) + (ax2.inner.inner*256)) + (ax3*32)) + threadIdx.x)] = placeholder[((((((blockIdx.z*2048) + (threadIdx.z*512)) + (ax2.inner.inner*256)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  unrolled (ic.outer, 0, 2) {
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((ax2*2048) + (ic.outer*1024)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    unrolled (ax2, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
        placeholder.shared[(((ax2*128) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*2048) + (ax2*256)) + (ic.outer*128)) + (threadIdx.z*32)) + threadIdx.x)]
      }
    }
    unrolled (ax2, 0, 2) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.z*2048) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 4) {
      unrolled (n.c, 0, 8) {
        unrolled (o.c, 0, 2) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*2) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*2) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 2) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*2) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((n.inner*512) + (threadIdx.z*128)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 2) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_relu[((((((((blockIdx.z*65536) + (ax2.outer.inner*8192)) + (ax2.inner.ax3.inner.fused.outer*4096)) + (floordiv(threadIdx.x, 8)*1024)) + (blockIdx.y*64)) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((Conv[(((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + int32(shift_right(((int64(placeholder[((((((((blockIdx.z*65536) + (ax2.outer.inner*8192)) + (ax2.inner.ax3.inner.fused.outer*4096)) + (floordiv(threadIdx.x, 8)*1024)) + (blockIdx.y*64)) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])*(int64)1886303204) + (int64)1073741824), (int64)31))), 2147483647), 0)
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__3"} {
  // attr [compute] storage_scope = "global"
  allocate compute[uint4 * 4194304]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer, 0, 2) {
    for (h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner, 0, 8) {
      compute[((((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*262144) + (floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 16384)*2048)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 2048)), 8)*256)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 2048)/8))] = placeholder[((((((h.w.fused.n.fused.i.fused.nn.fused.ii.fused.outer.outer*262144) + (floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 16384)*2048)) + (floormod(((blockIdx.x*4) + floordiv(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 2048)), 8)*256)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 256), 32)*32)) + (floordiv(floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 2048), 256)*4)) + (floormod(((threadIdx.x*8) + h.w.fused.n.fused.i.fused.nn.fused.ii.fused.inner), 32)/8))]
    }
  }
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 196
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 4096]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 6144]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 2048]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 2048]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  for (ic.outer, 0, 4) {
    for (kh, 0, 3) {
      unrolled (ic.inner, 0, 2) {
        unrolled (ax1, 0, 3) {
          unrolled (ax2.inner.inner, 0, 8) {
            // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
            unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
              compute.shared[(((ax1*256) + (ax2.inner.inner*32)) + threadIdx.x)] = compute[((((((((floordiv(blockIdx.z, 14)*32768) + (kh*32768)) + (ax1*2048)) + (floormod(blockIdx.z, 14)*2048)) + (ax2.inner.inner*256)) + (ic.outer*64)) + (ic.inner*32)) + threadIdx.x)]
            }
          }
        }
        unrolled (kw, 0, 3) {
          unrolled (ax2, 0, 8) {
            tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, ((kw*2048) + (ax2*256)), 256, 1), 32, "row_major")
          }
          unrolled (ax2, 0, 8) {
            // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
            unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
              placeholder.shared[((ax2*32) + threadIdx.x)] = placeholder[(((((((kh*24576) + (kw*8192)) + (blockIdx.y*2048)) + (ax2*256)) + (ic.outer*64)) + (ic.inner*32)) + threadIdx.x)]
            }
          }
          unrolled (ax2, 0, 8) {
            tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), placeholder.shared, (ax2*256), 256, 1), 32, "col_major")
          }
          unrolled (n.c, 0, 8) {
            unrolled (o.c, 0, 8) {
              tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, n.c, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, ((n.c*8) + o.c))
            }
          }
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, ((n.inner*512) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 8) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[((((((blockIdx.z*2048) + (ax2.outer.inner*256)) + (ax2.inner.ax3.inner.fused.outer*128)) + (floordiv(threadIdx.x, 8)*32)) + (blockIdx.y*8)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((blockIdx.y*64) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_pad]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_pad_1"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 2) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      T_pad[((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)*2048)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*32)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)/8))] = tvm_if_then_else(((((262144 <= ((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner)) && (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 3932160)) && (16384 <= floormod((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 262144))) && (floormod((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 262144) < 245760)), placeholder[(((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*1835008) + (floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 262144)*229376)) + (floordiv(floormod((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 262144), 16384)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)) - 245760)/8)], 0)
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__4"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 196
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 16384]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 16384]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (n.c.init, 0, 4) {
    unrolled (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  for (ic.outer, 0, 4) {
    unrolled (ax2.inner.inner, 0, 4) {
      unrolled (ax3, 0, 8) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
          compute.shared[((((threadIdx.y*1024) + (ax2.inner.inner*256)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*8192) + (threadIdx.y*4096)) + (ax2.inner.inner*1024)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*128)) + (ic.outer*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
        }
      }
    }
    unrolled (ax2, 0, 4) {
      unrolled (ax3, 0, 8) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*8192) + (ax2*2048)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    unrolled (ax2, 0, 8) {
      unrolled (ax3.inner.inner, 0, 4) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
          compute.shared[((((ax2*256) + (threadIdx.y*128)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*8192) + (ax2*1024)) + (ic.outer*256)) + (threadIdx.y*128)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 8) {
      unrolled (n.c, 0, 4) {
        unrolled (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 4) {
    unrolled (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((threadIdx.y*2048) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (ax2.outer.inner, 0, 4) {
    unrolled (ax3.outer.inner, 0, 8) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*2048) + (threadIdx.y*1024)) + (ax2.outer.inner*256)) + (ax2.inner.ax3.inner.fused.outer*128)) + (floordiv(threadIdx.x, 8)*32)) + (blockIdx.y*8)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((blockIdx.y*64) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((threadIdx.y*2048) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_add_clip_cast_nn_relu_1"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 196
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 16384]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 16
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 2) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*2) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax2.inner.inner, 0, 2) {
    unrolled (ax3, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[((((threadIdx.z*512) + (ax2.inner.inner*256)) + (ax3*32)) + threadIdx.x)] = placeholder[((((((blockIdx.z*2048) + (threadIdx.z*512)) + (ax2.inner.inner*256)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  unrolled (ic.outer, 0, 2) {
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((ax2*2048) + (ic.outer*1024)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    unrolled (ax2, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
        placeholder.shared[(((ax2*128) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*2048) + (ax2*256)) + (ic.outer*128)) + (threadIdx.z*32)) + threadIdx.x)]
      }
    }
    unrolled (ax2, 0, 2) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.z*2048) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 4) {
      unrolled (n.c, 0, 8) {
        unrolled (o.c, 0, 2) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*2) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*2) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 2) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*2) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((n.inner*512) + (threadIdx.z*128)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 2) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_relu[((((((((blockIdx.z*65536) + (ax2.outer.inner*8192)) + (ax2.inner.ax3.inner.fused.outer*4096)) + (floordiv(threadIdx.x, 8)*1024)) + (blockIdx.y*64)) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((Conv[(((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + placeholder[((((((((blockIdx.z*65536) + (ax2.outer.inner*8192)) + (ax2.inner.ax3.inner.fused.outer*4096)) + (floordiv(threadIdx.x, 8)*1024)) + (blockIdx.y*64)) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]), 2147483647), 0)
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__5"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 196
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 32768]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 4) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*4) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax2.inner.inner, 0, 4) {
    unrolled (ax3, 0, 16) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[((((threadIdx.z*2048) + (ax2.inner.inner*512)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((floordiv(blockIdx.z, 14)*229376) + (floormod(blockIdx.z, 14)*8192)) + (threadIdx.z*2048)) + (ax2.inner.inner*512)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*64)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  unrolled (ic.outer, 0, 4) {
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((ax2*4096) + (ic.outer*1024)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    unrolled (ax2, 0, 8) {
      unrolled (ax3.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
          placeholder.shared[((((ax2*128) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*4096) + (ax2*512)) + (ic.outer*128)) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    unrolled (ax2, 0, 4) {
      unrolled (ax3, 0, 4) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.z*4096) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 4) {
      unrolled (n.c, 0, 8) {
        unrolled (o.c, 0, 4) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*4) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*4) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 4) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*4) + o.inner), tvm_access_ptr(type_annotation(), compute.shared, (((n.inner*512) + (threadIdx.z*256)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 4) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*2048) + (ax2.outer.inner*256)) + (ax2.inner.ax3.inner.fused.outer*128)) + (floordiv(threadIdx.x, 8)*32)) + (blockIdx.y*8)) + (threadIdx.z*4)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[(((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[(((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_cast_cast_left_shift_multiply_add_right_shift_cast_clip_cast_2"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 13) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 25690112)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 3211264)) {
          T_cast[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*114688) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*4096)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*64)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)/8))] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8))]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 1)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 2)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 3)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 4)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 5)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 6)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*64) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 32768)), 28)*32768)) + (floormod(((blockIdx.x*16) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512)), 64)*512)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 512), 8)*8)) + 7)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15)))
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_cast_cast_multiply_add_right_shift_cast_add_clip_cast_n_16373524651668054328__2"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 784
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 256]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 256]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 256]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 4096]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 1024]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 1024]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 8
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  for (o.c.init, 0, 4) {
    tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, o.c.init, 0f)
  }
  for (ic.outer, 0, 4) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    for (ax4.ax5.fused.inner.outer, 0, 8) {
      if ((threadIdx.z < 1)) {
        compute.shared[((threadIdx.z*32) + threadIdx.x)] = placeholder[((((((blockIdx.z*1024) + (threadIdx.z*128)) + (blockIdx.x*128)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*16)) + (ic.outer*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
    tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, 0, tvm_access_ptr(type_annotation(), compute.shared, 0, 256, 1), 32, "row_major")
    for (ax2, 0, 16) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      if ((threadIdx.z < 1)) {
        placeholder.shared[(((ax2*32) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*2048) + (ax2*128)) + (ic.outer*32)) + (threadIdx.z*32)) + threadIdx.x)]
      }
    }
    for (ax2, 0, 4) {
      tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), placeholder.shared, ((threadIdx.z*1024) + (ax2*256)), 256, 1), 32, "col_major")
    }
    for (o.c, 0, 4) {
      tvm_mma_sync(Conv.wmma.accumulator, o.c, compute.shared.wmma.matrix_a, 0, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, o.c)
    }
  }
  for (o.inner, 0, 4) {
    tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, o.inner, tvm_access_ptr(type_annotation(), Conv, ((threadIdx.z*256) + (o.inner*64)), 64, 2), 8, "row_major")
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  for (ax3.outer.inner, 0, 4) {
    for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      T_relu[((((((((blockIdx.z*32768) + (blockIdx.x*4096)) + (ax2.inner.ax3.inner.fused.outer*2048)) + (floordiv(threadIdx.x, 8)*512)) + (blockIdx.y*128)) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((Conv[((((threadIdx.z*256) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + int32(shift_right(((int64(placeholder[((((((((blockIdx.z*32768) + (blockIdx.x*4096)) + (ax2.inner.ax3.inner.fused.outer*2048)) + (floordiv(threadIdx.x, 8)*512)) + (blockIdx.y*128)) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])*(int64)1886303204) + (int64)1073741824), (int64)31))), 2147483647), 0)
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__6"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 784
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 8192]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 2) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*2) + o.c.init), 0f)
    }
  }
  for (kh, 0, 3) {
    unrolled (kw, 0, 3) {
      unrolled (ax2.inner.inner, 0, 2) {
        unrolled (ax3, 0, 4) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
            compute.shared[((((threadIdx.z*256) + (ax2.inner.inner*128)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((((floordiv(blockIdx.z, 28)*30720) + (kh*30720)) + (kw*1024)) + (floormod(blockIdx.z, 28)*1024)) + (threadIdx.z*256)) + (ax2.inner.inner*128)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*16)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
          }
        }
      }
      unrolled (ax2, 0, 8) {
        unrolled (ax3, 0, 4) {
          tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*1024) + (ax3*256)), 256, 1), 32, "row_major")
        }
      }
      // attr [placeholder.shared] double_buffer_scope = 1
      unrolled (ax2, 0, 8) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        compute.shared[(((ax2*128) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[((((((kh*6144) + (kw*2048)) + (blockIdx.y*1024)) + (ax2*128)) + (threadIdx.z*32)) + threadIdx.x)]
      }
      unrolled (ax2, 0, 2) {
        unrolled (ax3, 0, 4) {
          tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.z*2048) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
        }
      }
      unrolled (ic.inner, 0, 4) {
        unrolled (n.c, 0, 8) {
          unrolled (o.c, 0, 2) {
            tvm_mma_sync(Conv.wmma.accumulator, ((n.c*2) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*2) + o.c))
          }
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 2) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*2) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((n.inner*512) + (threadIdx.z*128)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 2) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*1024) + (ax2.outer.inner*128)) + (ax2.inner.ax3.inner.fused.outer*64)) + (floordiv(threadIdx.x, 8)*16)) + (blockIdx.y*8)) + (threadIdx.z*2)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[(((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*128)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[((((blockIdx.y*64) + (threadIdx.z*16)) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_pad]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_pad_2"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 4) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 7372800)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 921600)) {
          T_pad[(((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 245760)*30720) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*256) + blockIdx.x), 30)*1024)) + threadIdx.x)] = tvm_if_then_else(((((245760 <= ((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner)) && (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 7127040)) && (1 <= floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*256) + blockIdx.x), 30))) && (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*256) + blockIdx.x), 30) < 29)), placeholder[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 245760)*28672) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*256) + blockIdx.x), 30)*1024)) + threadIdx.x) - 29696)], 0)
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__7"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 784
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 16384]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 32768]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 16384]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 2
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (n.c.init, 0, 4) {
    unrolled (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  unrolled (ax2.inner.inner, 0, 2) {
    unrolled (ax3, 0, 16) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[((((threadIdx.z*1024) + (ax2.inner.inner*512)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*4096) + (blockIdx.x*2048)) + (threadIdx.z*1024)) + (ax2.inner.inner*512)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*64)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  for (ic.outer, 0, 2) {
    unrolled (ax2, 0, 4) {
      unrolled (ax3, 0, 8) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((ax2*4096) + (ic.outer*2048)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    unrolled (ax2, 0, 16) {
      unrolled (ax3.inner.inner, 0, 4) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
          placeholder.shared[((((ax2*256) + (threadIdx.z*128)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[(((((ax2*512) + (ic.outer*256)) + (threadIdx.z*128)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    unrolled (ax2, 0, 8) {
      unrolled (ax3, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.z*16384) + (ax2*2048)) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    unrolled (ic.inner, 0, 8) {
      unrolled (n.c, 0, 4) {
        unrolled (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 4) {
    unrolled (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), placeholder.shared, (((n.inner*1024) + (threadIdx.z*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (ax2.outer.inner, 0, 4) {
    unrolled (ax3.outer.inner, 0, 8) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*1024) + (blockIdx.x*512)) + (ax2.outer.inner*128)) + (ax2.inner.ax3.inner.fused.outer*64)) + (floordiv(threadIdx.x, 8)*16)) + (threadIdx.z*8)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((threadIdx.z*64) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((threadIdx.z*64) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_add_clip_cast_nn_relu_2"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 784
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 256]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 256]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 256]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 4096]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 1024]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 1024]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 8
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  for (o.c.init, 0, 4) {
    tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, o.c.init, 0f)
  }
  for (ic.outer, 0, 4) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    for (ax4.ax5.fused.inner.outer, 0, 8) {
      if ((threadIdx.z < 1)) {
        compute.shared[((threadIdx.z*32) + threadIdx.x)] = placeholder[((((((blockIdx.z*1024) + (threadIdx.z*128)) + (blockIdx.x*128)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*16)) + (ic.outer*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
    tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, 0, tvm_access_ptr(type_annotation(), compute.shared, 0, 256, 1), 32, "row_major")
    for (ax2, 0, 16) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      if ((threadIdx.z < 1)) {
        placeholder.shared[(((ax2*32) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*2048) + (ax2*128)) + (ic.outer*32)) + (threadIdx.z*32)) + threadIdx.x)]
      }
    }
    for (ax2, 0, 4) {
      tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), placeholder.shared, ((threadIdx.z*1024) + (ax2*256)), 256, 1), 32, "col_major")
    }
    for (o.c, 0, 4) {
      tvm_mma_sync(Conv.wmma.accumulator, o.c, compute.shared.wmma.matrix_a, 0, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, o.c)
    }
  }
  for (o.inner, 0, 4) {
    tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, o.inner, tvm_access_ptr(type_annotation(), Conv, ((threadIdx.z*256) + (o.inner*64)), 64, 2), 8, "row_major")
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 4
  for (ax3.outer.inner, 0, 4) {
    for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      T_relu[((((((((blockIdx.z*32768) + (blockIdx.x*4096)) + (ax2.inner.ax3.inner.fused.outer*2048)) + (floordiv(threadIdx.x, 8)*512)) + (blockIdx.y*128)) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((Conv[((((threadIdx.z*256) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + placeholder[((((((((blockIdx.z*32768) + (blockIdx.x*4096)) + (ax2.inner.ax3.inner.fused.outer*2048)) + (floordiv(threadIdx.x, 8)*512)) + (blockIdx.y*128)) + (threadIdx.z*32)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]), 2147483647), 0)
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__8"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 784
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 4096]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 4096]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 16384]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 16384]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 4
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (n.c.init, 0, 2) {
    unrolled (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax2.inner.inner, 0, 2) {
    unrolled (ax3, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[(((ax2.inner.inner*256) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((floordiv(blockIdx.z, 28)*229376) + (floormod(blockIdx.z, 28)*4096)) + (blockIdx.x*512)) + (ax2.inner.inner*256)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  unrolled (ax2, 0, 2) {
    unrolled (ax3, 0, 8) {
      tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "row_major")
    }
  }
  // attr [placeholder.shared] double_buffer_scope = 1
  unrolled (ax2, 0, 8) {
    unrolled (ax3.inner.inner, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      placeholder.shared[(((ax2*256) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((blockIdx.y*2048) + (ax2*256)) + (ax3.inner.inner*32)) + threadIdx.x)]
    }
  }
  unrolled (ax2, 0, 8) {
    unrolled (ax3, 0, 8) {
      tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "col_major")
    }
  }
  unrolled (ic.inner, 0, 8) {
    unrolled (n.c, 0, 2) {
      unrolled (o.c, 0, 8) {
        tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
      }
    }
  }
  unrolled (n.inner, 0, 2) {
    unrolled (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), placeholder.shared, ((n.inner*512) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (ax2.outer.inner, 0, 2) {
    unrolled (ax3.outer.inner, 0, 8) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((blockIdx.z*1024) + (blockIdx.x*256)) + (ax2.outer.inner*128)) + (ax2.inner.ax3.inner.fused.outer*64)) + (floordiv(threadIdx.x, 8)*16)) + (blockIdx.y*8)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((blockIdx.y*64) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((placeholder.shared[(((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
      }
    }
  }
}


PrimFunc([placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_cast_cast_left_shift_multiply_add_right_shift_cast_clip_cast_3"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 25) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 51380224)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 6422528)) {
          T_cast[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*114688) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*2048)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*32)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)/8))] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8))]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 1)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 2)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 3)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 4)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 5)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 6)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 917504)*917504) + (floormod(((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*128) + floordiv((((blockIdx.x*8192) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 16384)), 56)*16384)) + (floormod(((blockIdx.x*32) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256)), 64)*256)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 256), 8)*8)) + 7)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15)))
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_cast_cast_multiply_add_right_shift_cast_add_clip_cast_n_16373524651668054328__3"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 1568
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 4096]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 2048]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 2048]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  for (ax0.inner.ax1.fused.inner, 0, 2) {
    // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
    // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    for (n.c.init, 0, 8) {
      for (o.c.init, 0, 8) {
        tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
      }
    }
    for (ic.outer, 0, 2) {
      for (ax2.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.outer, 0, 8) {
          compute.shared[(((threadIdx.y*64) + (ax2.inner.inner*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*1024) + (ax0.inner.ax1.fused.inner*512)) + (threadIdx.y*128)) + (ax2.inner.inner*64)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*8)) + (ic.outer*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
        }
      }
      for (ax2, 0, 8) {
        if ((((threadIdx.y*8) + ax2) < 8)) {
          tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, ((threadIdx.y*2048) + (ax2*256)), 256, 1), 32, "row_major")
        }
      }
      // attr [placeholder.shared] double_buffer_scope = 1
      for (ax2, 0, 8) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.inner, 0, 8) {
          if ((threadIdx.y < 1)) {
            compute.shared[(((ax2*32) + (threadIdx.y*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*512) + (ax2*64)) + (ic.outer*32)) + (threadIdx.y*32)) + threadIdx.x)]
          }
        }
      }
      for (ax2, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, (ax2*256), 256, 1), 32, "col_major")
      }
      for (n.c, 0, 8) {
        for (o.c, 0, 8) {
          if ((((threadIdx.y*8) + n.c) < 8)) {
            tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, n.c, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, ((n.c*8) + o.c))
          }
        }
      }
    }
    for (n.inner, 0, 8) {
      for (o.inner, 0, 8) {
        if ((((threadIdx.y*8) + n.inner) < 8)) {
          if ((threadIdx.y < 1)) {
            tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((threadIdx.y*4096) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
          }
        }
      }
    }
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    for (ax2.outer.inner, 0, 8) {
      for (ax3.outer.inner, 0, 8) {
        for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          if ((((((threadIdx.y*64) + (ax2.outer.inner*8)) + (ax2.inner.ax3.inner.fused.outer*4)) + floordiv(threadIdx.x, 8)) < 64)) {
            if ((((threadIdx.y*8) + ax2.outer.inner) < 8)) {
              if ((threadIdx.y < 1)) {
                T_relu[(((((((((blockIdx.z*32768) + (ax0.inner.ax1.fused.inner*16384)) + (threadIdx.y*16384)) + (ax2.outer.inner*2048)) + (ax2.inner.ax3.inner.fused.outer*1024)) + (floordiv(threadIdx.x, 8)*256)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((Conv[(((((threadIdx.y*4096) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + int32(shift_right(((int64(placeholder[(((((((((blockIdx.z*32768) + (ax0.inner.ax1.fused.inner*16384)) + (threadIdx.y*16384)) + (ax2.outer.inner*2048)) + (ax2.inner.ax3.inner.fused.outer*1024)) + (floordiv(threadIdx.x, 8)*256)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])*(int64)1886303204) + (int64)1073741824), (int64)31))), 2147483647), 0)
              }
            }
          }
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__9"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 1568
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 4096]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 4096]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  for (ax0.inner.ax1.fused.inner, 0, 2) {
    // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
    // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 1
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
    unrolled (n.c.init, 0, 8) {
      unrolled (o.c.init, 0, 4) {
        tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*4) + o.c.init), 0f)
      }
    }
    unrolled (kh, 0, 3) {
      unrolled (kw, 0, 3) {
        // attr [compute.shared] double_buffer_scope = 1
        unrolled (ax2.inner.inner, 0, 4) {
          unrolled (ax3, 0, 2) {
            // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
            unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
              compute.shared[((((threadIdx.z*256) + (ax2.inner.inner*64)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((((floordiv(((blockIdx.z*2) + ax0.inner.ax1.fused.inner), 56)*29696) + (kh*29696)) + (kw*512)) + (floormod(((blockIdx.z*2) + ax0.inner.ax1.fused.inner), 56)*512)) + (threadIdx.z*256)) + (ax2.inner.inner*64)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*8)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
            }
          }
        }
        unrolled (ax2, 0, 8) {
          unrolled (ax3, 0, 2) {
            tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*2) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*512) + (ax3*256)), 256, 1), 32, "row_major")
          }
        }
        // attr [placeholder.shared] double_buffer_scope = 1
        unrolled (ax2, 0, 8) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          compute.shared[(((ax2*64) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[(((((kh*1536) + (kw*512)) + (ax2*64)) + (threadIdx.z*32)) + threadIdx.x)]
        }
        unrolled (ax2, 0, 4) {
          unrolled (ax3, 0, 2) {
            tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*2) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.z*2048) + (ax2*512)) + (ax3*256)), 256, 1), 32, "col_major")
          }
        }
        unrolled (ic.inner, 0, 2) {
          unrolled (n.c, 0, 8) {
            unrolled (o.c, 0, 4) {
              tvm_mma_sync(Conv.wmma.accumulator, ((n.c*4) + o.c), compute.shared.wmma.matrix_a, ((n.c*2) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*2) + ic.inner), Conv.wmma.accumulator, ((n.c*4) + o.c))
            }
          }
        }
      }
    }
    unrolled (n.inner, 0, 8) {
      unrolled (o.inner, 0, 4) {
        tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*4) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((n.inner*512) + (threadIdx.z*256)) + (o.inner*64)), 64, 2), 8, "row_major")
      }
    }
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
    unrolled (ax2.outer.inner, 0, 8) {
      unrolled (ax3.outer.inner, 0, 4) {
        unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          T_cast[(((((((blockIdx.z*1024) + (ax0.inner.ax1.fused.inner*512)) + (ax2.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + (threadIdx.z*4)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((threadIdx.z*32) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((((ax2.outer.inner*512) + (threadIdx.z*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((threadIdx.z*32) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
        }
      }
    }
  }
}


PrimFunc([placeholder, T_pad]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_pad_3"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 7) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 13778944)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 1722368)) {
          T_pad[(((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 237568)*29696) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 58)*512)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)/8))] = tvm_if_then_else(((((237568 <= ((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner)) && (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 13541376)) && (1 <= floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 58))) && (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 58) < 57)), placeholder[((((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 237568)*28672) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 58)*512)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)/8)) - 29184)], 0)
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__10"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 3136
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 16384]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 2048]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 1024]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 1024]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (n.c.init, 0, 8) {
    unrolled (o.c.init, 0, 4) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*4) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax2.inner.inner, 0, 4) {
    unrolled (ax3, 0, 8) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
        compute.shared[((((threadIdx.y*1024) + (ax2.inner.inner*256)) + (ax3*32)) + threadIdx.x)] = placeholder[((((((blockIdx.z*2048) + (threadIdx.y*1024)) + (ax2.inner.inner*256)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
      }
    }
  }
  unrolled (ic.outer, 0, 8) {
    unrolled (ax2, 0, 8) {
      if ((((threadIdx.y*8) + ax2) < 8)) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*16384) + (ax2*2048)) + (ic.outer*256)), 256, 1), 32, "row_major")
      }
    }
    unrolled (ax2, 0, 4) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      if ((threadIdx.y < 1)) {
        placeholder.shared[(((ax2*32) + (threadIdx.y*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*1024) + (ax2*256)) + (ic.outer*32)) + (threadIdx.y*32)) + threadIdx.x)]
      }
    }
    unrolled (ax2, 0, 4) {
      tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), placeholder.shared, (ax2*256), 256, 1), 32, "col_major")
    }
    unrolled (n.c, 0, 8) {
      unrolled (o.c, 0, 4) {
        if ((((threadIdx.y*8) + n.c) < 8)) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*4) + o.c), compute.shared.wmma.matrix_a, n.c, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, ((n.c*4) + o.c))
        }
      }
    }
  }
  unrolled (n.inner, 0, 8) {
    unrolled (o.inner, 0, 4) {
      if ((((threadIdx.y*8) + n.inner) < 8)) {
        if ((threadIdx.y < 1)) {
          tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*4) + o.inner), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*2048) + (n.inner*256)) + (o.inner*64)), 64, 2), 8, "row_major")
        }
      }
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  unrolled (ax2.outer.inner, 0, 8) {
    unrolled (ax3.outer.inner, 0, 4) {
      unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        if ((((((threadIdx.y*64) + (ax2.outer.inner*8)) + (ax2.inner.ax3.inner.fused.outer*4)) + floordiv(threadIdx.x, 8)) < 64)) {
          if ((((threadIdx.y*8) + ax2.outer.inner) < 8)) {
            if ((threadIdx.y < 1)) {
              T_cast[(((((((blockIdx.z*512) + (threadIdx.y*512)) + (ax2.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + (blockIdx.y*4)) + ax3.outer.inner)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[(((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((blockIdx.y*32) + (ax3.outer.inner*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((compute.shared[((((((threadIdx.y*2048) + (ax2.outer.inner*256)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((blockIdx.y*32) + (ax3.outer.inner*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
            }
          }
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_add_clip_cast_nn_relu_3"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 1568
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 4096]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 2048]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 2048]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  for (ax0.inner.ax1.fused.inner, 0, 2) {
    // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
    // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    for (n.c.init, 0, 8) {
      for (o.c.init, 0, 8) {
        tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
      }
    }
    for (ic.outer, 0, 2) {
      for (ax2.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.outer, 0, 8) {
          compute.shared[(((threadIdx.y*64) + (ax2.inner.inner*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*1024) + (ax0.inner.ax1.fused.inner*512)) + (threadIdx.y*128)) + (ax2.inner.inner*64)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*8)) + (ic.outer*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
        }
      }
      for (ax2, 0, 8) {
        if ((((threadIdx.y*8) + ax2) < 8)) {
          tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, ((threadIdx.y*2048) + (ax2*256)), 256, 1), 32, "row_major")
        }
      }
      // attr [placeholder.shared] double_buffer_scope = 1
      for (ax2, 0, 8) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.inner, 0, 8) {
          if ((threadIdx.y < 1)) {
            compute.shared[(((ax2*32) + (threadIdx.y*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*512) + (ax2*64)) + (ic.outer*32)) + (threadIdx.y*32)) + threadIdx.x)]
          }
        }
      }
      for (ax2, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, (ax2*256), 256, 1), 32, "col_major")
      }
      for (n.c, 0, 8) {
        for (o.c, 0, 8) {
          if ((((threadIdx.y*8) + n.c) < 8)) {
            tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, n.c, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, ((n.c*8) + o.c))
          }
        }
      }
    }
    for (n.inner, 0, 8) {
      for (o.inner, 0, 8) {
        if ((((threadIdx.y*8) + n.inner) < 8)) {
          if ((threadIdx.y < 1)) {
            tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((threadIdx.y*4096) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
          }
        }
      }
    }
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    for (ax2.outer.inner, 0, 8) {
      for (ax3.outer.inner, 0, 8) {
        for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          if ((((((threadIdx.y*64) + (ax2.outer.inner*8)) + (ax2.inner.ax3.inner.fused.outer*4)) + floordiv(threadIdx.x, 8)) < 64)) {
            if ((((threadIdx.y*8) + ax2.outer.inner) < 8)) {
              if ((threadIdx.y < 1)) {
                T_relu[(((((((((blockIdx.z*32768) + (ax0.inner.ax1.fused.inner*16384)) + (threadIdx.y*16384)) + (ax2.outer.inner*2048)) + (ax2.inner.ax3.inner.fused.outer*1024)) + (floordiv(threadIdx.x, 8)*256)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = max(min(((Conv[(((((threadIdx.y*4096) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]) + placeholder[(((((((((blockIdx.z*32768) + (ax0.inner.ax1.fused.inner*16384)) + (threadIdx.y*16384)) + (ax2.outer.inner*2048)) + (ax2.inner.ax3.inner.fused.outer*1024)) + (floordiv(threadIdx.x, 8)*256)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))]), 2147483647), 0)
              }
            }
          }
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_nn_relu_cast_cast_left_shift_multiply_add_right_shift_cast_c_3441552496575213188__11"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 3136
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 64]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 2048]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 512]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 512]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 512]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 2
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, 0, 0f)
  // attr [compute.shared] double_buffer_scope = 1
  unrolled (ax3, 0, 2) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
      if (((threadIdx.z + threadIdx.y) < 4)) {
        if ((threadIdx.z < 1)) {
          compute.shared[((((threadIdx.z*64) + (threadIdx.y*64)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*512) + (blockIdx.x*256)) + (threadIdx.z*64)) + (threadIdx.y*64)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*8)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
        }
      }
    }
  }
  unrolled (ax3, 0, 2) {
    tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ax3, tvm_access_ptr(type_annotation(), compute.shared, ((threadIdx.y*512) + (ax3*256)), 256, 1), 32, "row_major")
  }
  unrolled (ax2, 0, 2) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
      if (((threadIdx.z + threadIdx.y) < 2)) {
        if ((threadIdx.z < 1)) {
          compute.shared[((((ax2*64) + (threadIdx.y*32)) + (threadIdx.z*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*128) + (ax2*64)) + (threadIdx.y*32)) + (threadIdx.z*32)) + threadIdx.x)]
        }
      }
    }
  }
  unrolled (ax3, 0, 2) {
    tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax3, tvm_access_ptr(type_annotation(), compute.shared, ((threadIdx.z*512) + (ax3*256)), 256, 1), 32, "col_major")
  }
  unrolled (ic.inner, 0, 2) {
    tvm_mma_sync(Conv.wmma.accumulator, 0, compute.shared.wmma.matrix_a, ic.inner, placeholder.shared.wmma.matrix_b, ic.inner, Conv.wmma.accumulator, 0)
  }
  tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, 0, tvm_access_ptr(type_annotation(), Conv, ((threadIdx.y*128) + (threadIdx.z*64)), 64, 2), 8, "row_major")
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    T_cast[(((((((blockIdx.z*512) + (blockIdx.x*256)) + (threadIdx.y*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + (blockIdx.y*2)) + threadIdx.z)] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8))] + placeholder[((blockIdx.y*16) + (threadIdx.z*8))]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 1)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 1)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 2)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 2)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 3)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 3)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 4)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 4)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 5)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 5)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 6)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 6)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(max((Conv[(((((threadIdx.y*128) + (threadIdx.z*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + (floordiv(threadIdx.x, 8)*8)) + 7)] + placeholder[(((blockIdx.y*16) + (threadIdx.z*8)) + 7)]), 0)), (int64)4)*(int64)1241513984) + (int64)1073741824), (int64)31)), 15), 0), 15)))
  }
}


PrimFunc([placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_transpose_cast_cast_left_shift_multiply_add_right_shift_cast_clip_cast"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer, 0, 7) {
    for (ax0.ax1.fused.ax2.fused.ax3.fused.inner, 0, 8) {
      if ((((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner) < 12845056)) {
        if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 1605632)) {
          T_cast[(((floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*28672) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*512)) + (floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)/8))] = uint4(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(bitwise_or(0, shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8))]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 28)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 1)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 24)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 2)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 20)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 3)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 16)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 4)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 12)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 5)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 8)), shift_left(bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 6)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15), 4)), bitwise_and(max(min(int32(shift_right(((shift_left(int64(placeholder[(((((floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096), 64)*200704) + (floordiv(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*2097152) + (blockIdx.x*8192)) + (threadIdx.x*8)) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 229376)*3584)) + (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer.outer*512) + (blockIdx.x*2)) + floordiv(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 4096)), 56)*64)) + (floordiv(floormod(((threadIdx.x*8) + ax0.ax1.fused.ax2.fused.ax3.fused.inner), 64), 8)*8)) + 7)]), (int64)4)*(int64)1090519040) + (int64)1073741824), (int64)31)), 15), 0), 15)))
        }
      }
    }
  }
}


PrimFunc([placeholder, tensor]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_max_pool2d"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 12544
  // attr [tensor.local] storage_scope = "local"
  allocate tensor.local[int32 * 1]
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  tensor.local[0] = -2147483648
  for (rv, 0, 3) {
    for (rv, 0, 3) {
      tensor.local[0] = max(tensor.local[0], tvm_if_then_else(((1 <= ((floordiv(floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 3136), 56)*2) + rv)) && (1 <= ((floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 56)*2) + rv))), placeholder[((((((floordiv(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 56)*14336) + (rv*7168)) + (floormod(((blockIdx.x*16) + floordiv(threadIdx.x, 64)), 56)*128)) + (rv*64)) + floormod(threadIdx.x, 64)) - 7232)], -2147483648))
    }
  }
  tensor[((blockIdx.x*1024) + threadIdx.x)] = tensor.local[0]
}


PrimFunc([placeholder, placeholder, placeholder, T_relu]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_cast_multiply_add_right_shift_cast_nn_relu"} {
  // attr [kernel_im2col_pack] storage_scope = "global"
  allocate kernel_im2col_pack[int8 * 10240]
  // attr [gemm_C] storage_scope = "global"
  allocate gemm_C[int32 * 51380224]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 10
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  kernel_im2col_pack[((blockIdx.x*1024) + threadIdx.x)] = tvm_if_then_else((((floormod(((blockIdx.x*4) + floordiv(threadIdx.x, 256)), 10)*16) + floormod(threadIdx.x, 16)) < 147), placeholder[((((floordiv(((floormod(((blockIdx.x*4) + floordiv(threadIdx.x, 256)), 10)*16) + floormod(threadIdx.x, 16)), 3)*192) + (floordiv(((blockIdx.x*4) + floordiv(threadIdx.x, 256)), 10)*48)) + (floordiv(floormod(threadIdx.x, 256), 16)*3)) + floormod(((floormod(((blockIdx.x*4) + floordiv(threadIdx.x, 256)), 10)*16) + floormod(threadIdx.x, 16)), 3))], (int8)0)
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 6272
  // attr [gemm_C.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate gemm_C.wmma.accumulator[int32 * 2048]
  // attr [data_im2col_pack.shared] storage_scope = "shared"
  allocate data_im2col_pack.shared[int8 * 20480]
  // attr [kernel_im2col_pack.shared] storage_scope = "shared"
  allocate kernel_im2col_pack.shared[int8 * 10240]
  // attr [data_im2col_pack.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate data_im2col_pack.shared.wmma.matrix_a[int8 * 512]
  // attr [kernel_im2col_pack.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate kernel_im2col_pack.shared.wmma.matrix_b[int8 * 1024]
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
  for (i.c.init, 0, 2) {
    for (j.c.init, 0, 4) {
      tvm_fill_fragment(gemm_C.wmma.accumulator, 16, 16, 16, ((i.c.init*4) + j.c.init), 0f)
    }
  }
  for (ax0.inner, 0, 2) {
    for (ax1.inner, 0, 10) {
      // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
      for (ax2.ax3.fused.inner.outer, 0, 2) {
        for (ax2.ax3.fused.inner.inner.s, 0, 4) {
          data_im2col_pack.shared[((((((threadIdx.y*5120) + (ax0.inner*2560)) + (ax1.inner*256)) + (threadIdx.x*8)) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s)] = tvm_if_then_else((((ax1.inner*16) + floormod((((threadIdx.x*8) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s), 16)) < 147), placeholder[(((((floordiv(((((blockIdx.x*128) + (threadIdx.y*32)) + (ax0.inner*16)) + floordiv((((threadIdx.x*8) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s), 16)), 12544)*158700) + (floordiv(floormod(((((blockIdx.x*128) + (threadIdx.y*32)) + (ax0.inner*16)) + floordiv((((threadIdx.x*8) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s), 16)), 12544), 112)*1380)) + (floordiv(((ax1.inner*16) + floormod((((threadIdx.x*8) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s), 16)), 21)*690)) + (floormod(((((blockIdx.x*128) + (threadIdx.y*32)) + (ax0.inner*16)) + floordiv((((threadIdx.x*8) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s), 16)), 112)*6)) + floormod(((ax1.inner*16) + floormod((((threadIdx.x*8) + (ax2.ax3.fused.inner.outer*4)) + ax2.ax3.fused.inner.inner.s), 16)), 21))], (int8)0)
        }
      }
    }
  }
  for (ax1.inner, 0, 10) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    for (ax2.ax3.fused.inner.outer, 0, 2) {
      kernel_im2col_pack.shared[ramp(((((threadIdx.y*2560) + (ax1.inner*256)) + (threadIdx.x*8)) + (ax2.ax3.fused.inner.outer*4)), 1, 4)] = kernel_im2col_pack[ramp(((((threadIdx.y*2560) + (ax1.inner*256)) + (threadIdx.x*8)) + (ax2.ax3.fused.inner.outer*4)), 1, 4)]
    }
  }
  for (k1.inner, 0, 10) {
    for (ax0, 0, 2) {
      tvm_load_matrix_sync(data_im2col_pack.shared.wmma.matrix_a, 16, 16, 16, ax0, tvm_access_ptr(type_annotation(), data_im2col_pack.shared, (((threadIdx.y*5120) + (ax0*2560)) + (k1.inner*256)), 256, 1), 16, "row_major")
    }
    for (ax0, 0, 4) {
      tvm_load_matrix_sync(kernel_im2col_pack.shared.wmma.matrix_b, 16, 16, 16, ax0, tvm_access_ptr(type_annotation(), kernel_im2col_pack.shared, ((ax0*2560) + (k1.inner*256)), 256, 1), 16, "col_major")
    }
    for (i.c, 0, 2) {
      for (j.c, 0, 4) {
        tvm_mma_sync(gemm_C.wmma.accumulator, ((i.c*4) + j.c), data_im2col_pack.shared.wmma.matrix_a, i.c, kernel_im2col_pack.shared.wmma.matrix_b, j.c, gemm_C.wmma.accumulator, ((i.c*4) + j.c))
      }
    }
  }
  for (i.inner, 0, 2) {
    for (j.inner, 0, 4) {
      tvm_store_matrix_sync(gemm_C.wmma.accumulator, 16, 16, 16, ((i.inner*4) + j.inner), tvm_access_ptr(type_annotation(), gemm_C, ((((blockIdx.x*8192) + (threadIdx.y*2048)) + (i.inner*1024)) + (j.inner*256)), 256, 2), 16, "row_major")
    }
  }
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer, 0, 196) {
    T_relu[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = max(int32(shift_right(((int64((gemm_C[(((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + (floordiv(floormod(threadIdx.x, 64), 16)*256)) + (floordiv(threadIdx.x, 64)*16)) + floormod(threadIdx.x, 16))] + placeholder[floormod(threadIdx.x, 64)]))*(int64)1857283155) + (int64)1073741824), (int64)31)), 0)
  }
}


PrimFunc([placeholder, T_pad]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_pad_4"} {
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 256
  // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 1024
  for (ax0.ax1.fused.ax2.fused.ax3.fused.outer, 0, 39) {
    if (((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x) < 10156800)) {
      T_pad[(((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x)] = tvm_if_then_else(((((2070 <= floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 158700)) && (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 158700) < 156630)) && (9 <= floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 690))) && (floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 690) < 681)), placeholder[((((floordiv((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 158700)*150528) + (floordiv(floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 158700), 690)*672)) + floormod((((ax0.ax1.fused.ax2.fused.ax3.fused.outer*262144) + (blockIdx.x*1024)) + threadIdx.x), 690)) - 2025)], (int8)0)
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 1568
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 4096]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 2048]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 2048]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 2048]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  for (ax0.inner.ax1.fused.inner, 0, 2) {
    // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
    // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    for (n.c.init, 0, 8) {
      for (o.c.init, 0, 8) {
        tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
      }
    }
    for (ic.outer, 0, 2) {
      for (ax2.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.outer, 0, 8) {
          compute.shared[(((threadIdx.y*64) + (ax2.inner.inner*32)) + threadIdx.x)] = placeholder[(((((((blockIdx.z*1024) + (ax0.inner.ax1.fused.inner*512)) + (threadIdx.y*128)) + (ax2.inner.inner*64)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*8)) + (ic.outer*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
        }
      }
      for (ax2, 0, 8) {
        if ((((threadIdx.y*8) + ax2) < 8)) {
          tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, ((threadIdx.y*2048) + (ax2*256)), 256, 1), 32, "row_major")
        }
      }
      // attr [placeholder.shared] double_buffer_scope = 1
      for (ax2, 0, 8) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.inner, 0, 8) {
          if ((threadIdx.y < 1)) {
            compute.shared[(((ax2*32) + (threadIdx.y*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*512) + (ax2*64)) + (ic.outer*32)) + (threadIdx.y*32)) + threadIdx.x)]
          }
        }
      }
      for (ax2, 0, 8) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ax2, tvm_access_ptr(type_annotation(), compute.shared, (ax2*256), 256, 1), 32, "col_major")
      }
      for (n.c, 0, 8) {
        for (o.c, 0, 8) {
          if ((((threadIdx.y*8) + n.c) < 8)) {
            tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, n.c, placeholder.shared.wmma.matrix_b, o.c, Conv.wmma.accumulator, ((n.c*8) + o.c))
          }
        }
      }
    }
    for (n.inner, 0, 8) {
      for (o.inner, 0, 8) {
        if ((((threadIdx.y*8) + n.inner) < 8)) {
          if ((threadIdx.y < 1)) {
            tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, (((threadIdx.y*4096) + (n.inner*512)) + (o.inner*64)), 64, 2), 8, "row_major")
          }
        }
      }
    }
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 4
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    for (ax2.outer.inner, 0, 8) {
      for (ax3.outer.inner, 0, 8) {
        for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          if ((((((threadIdx.y*64) + (ax2.outer.inner*8)) + (ax2.inner.ax3.inner.fused.outer*4)) + floordiv(threadIdx.x, 8)) < 64)) {
            if ((((threadIdx.y*8) + ax2.outer.inner) < 8)) {
              if ((threadIdx.y < 1)) {
                T_cast[(((((((((blockIdx.z*32768) + (ax0.inner.ax1.fused.inner*16384)) + (threadIdx.y*16384)) + (ax2.outer.inner*2048)) + (ax2.inner.ax3.inner.fused.outer*1024)) + (floordiv(threadIdx.x, 8)*256)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = (Conv[(((((threadIdx.y*4096) + (ax2.outer.inner*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])
              }
            }
          }
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_1"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 784
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 1024]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 4096]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 2048]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 16384]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 8192]
  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 4
  // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 4
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  for (n.c.init, 0, 2) {
    for (o.c.init, 0, 8) {
      tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
    }
  }
  // attr [compute.shared] double_buffer_scope = 1
  for (ax3, 0, 8) {
    // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
    for (ax4.ax5.fused.inner.outer, 0, 8) {
      compute.shared[(((threadIdx.z*256) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((floordiv(blockIdx.z, 28)*229376) + (floormod(blockIdx.z, 28)*4096)) + (blockIdx.x*512)) + (threadIdx.z*256)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
    }
  }
  for (ic.outer, 0, 2) {
    for (ax2, 0, 2) {
      for (ax3, 0, 4) {
        tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((ax2*2048) + (ic.outer*1024)) + (ax3*256)), 256, 1), 32, "row_major")
      }
    }
    // attr [placeholder.shared] double_buffer_scope = 1
    for (ax2, 0, 16) {
      for (ax3.inner.inner, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        for (ax4.ax5.fused.inner.inner, 0, 8) {
          placeholder.shared[((((ax2*128) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*4096) + (ax2*256)) + (ic.outer*128)) + (threadIdx.z*64)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
    }
    for (ax2, 0, 8) {
      for (ax3, 0, 4) {
        tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.z*8192) + (ax2*1024)) + (ax3*256)), 256, 1), 32, "col_major")
      }
    }
    for (ic.inner, 0, 4) {
      for (n.c, 0, 2) {
        for (o.c, 0, 8) {
          tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
        }
      }
    }
  }
  for (n.inner, 0, 2) {
    for (o.inner, 0, 8) {
      tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), placeholder.shared, (((n.inner*1024) + (threadIdx.z*512)) + (o.inner*64)), 64, 2), 8, "row_major")
    }
  }
  // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
  // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 2
  for (ax2.outer.inner, 0, 2) {
    for (ax3.outer.inner, 0, 8) {
      for (ax2.inner.ax3.inner.fused.outer, 0, 2) {
        // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
        T_cast[(((((((((blockIdx.z*32768) + (blockIdx.x*8192)) + (ax2.outer.inner*4096)) + (ax2.inner.ax3.inner.fused.outer*2048)) + (floordiv(threadIdx.x, 8)*512)) + (blockIdx.y*128)) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = (placeholder.shared[(((((ax2.outer.inner*1024) + (threadIdx.z*512)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[((((blockIdx.y*128) + (threadIdx.z*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_2"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 98
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 4096]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 8192]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 8192]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 8192]
  // attr [Conv] storage_scope = "shared"
  allocate Conv[int32 * 4096]
  for (ax0.inner.ax1.fused.inner, 0, 2) {
    // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 1
    // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 16
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    unrolled (n.c.init, 0, 8) {
      unrolled (o.c.init, 0, 8) {
        tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*8) + o.c.init), 0f)
      }
    }
    for (ic.outer, 0, 4) {
      unrolled (ax2.inner.inner, 0, 8) {
        unrolled (ax3, 0, 4) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
            compute.shared[(((ax2.inner.inner*128) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((floordiv(((blockIdx.z*2) + ax0.inner.ax1.fused.inner), 14)*229376) + (floormod(((blockIdx.z*2) + ax0.inner.ax1.fused.inner), 14)*8192)) + (ax2.inner.inner*512)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*64)) + (ic.outer*16)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
          }
        }
      }
      unrolled (ax2, 0, 8) {
        unrolled (ax3, 0, 4) {
          tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*1024) + (ax3*256)), 256, 1), 32, "row_major")
        }
      }
      unrolled (ax2, 0, 8) {
        unrolled (ax3.inner.inner, 0, 4) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          unrolled (ax4.ax5.fused.inner.inner, 0, 8) {
            compute.shared[(((ax2*128) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[(((((blockIdx.y*4096) + (ax2*512)) + (ic.outer*128)) + (ax3.inner.inner*32)) + threadIdx.x)]
          }
        }
      }
      unrolled (ax2, 0, 8) {
        unrolled (ax3, 0, 4) {
          tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*4) + ax3), tvm_access_ptr(type_annotation(), compute.shared, ((ax2*1024) + (ax3*256)), 256, 1), 32, "col_major")
        }
      }
      unrolled (ic.inner, 0, 4) {
        unrolled (n.c, 0, 8) {
          unrolled (o.c, 0, 8) {
            tvm_mma_sync(Conv.wmma.accumulator, ((n.c*8) + o.c), compute.shared.wmma.matrix_a, ((n.c*4) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*4) + ic.inner), Conv.wmma.accumulator, ((n.c*8) + o.c))
          }
        }
      }
    }
    unrolled (n.inner, 0, 8) {
      unrolled (o.inner, 0, 8) {
        tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*8) + o.inner), tvm_access_ptr(type_annotation(), Conv, ((n.inner*512) + (o.inner*64)), 64, 2), 8, "row_major")
      }
    }
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    unrolled (ax2.outer.inner, 0, 8) {
      unrolled (ax3.outer.inner, 0, 8) {
        unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          T_cast[((((((((blockIdx.z*131072) + (ax0.inner.ax1.fused.inner*65536)) + (ax2.outer.inner*8192)) + (ax2.inner.ax3.inner.fused.outer*4096)) + (floordiv(threadIdx.x, 8)*1024)) + (blockIdx.y*64)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = (Conv[((((ax2.outer.inner*512) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*64) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])
        }
      }
    }
  }
}


PrimFunc([placeholder, placeholder, placeholder, T_cast]) attrs={"tir.noalias": (bool)1, "global_symbol": "fused_nn_conv2d_add_cast_3"} {
  // attr [iter_var(blockIdx.z, , blockIdx.z)] thread_extent = 25
  // attr [Conv.wmma.accumulator] storage_scope = "wmma.accumulator"
  allocate Conv.wmma.accumulator[int32 * 2048]
  // attr [compute.shared] storage_scope = "shared"
  allocate compute.shared[uint4 * 8192]
  // attr [compute.shared.wmma.matrix_a] storage_scope = "wmma.matrix_a"
  allocate compute.shared.wmma.matrix_a[uint4 * 4096]
  // attr [placeholder.shared] storage_scope = "shared"
  allocate placeholder.shared[int4 * 32768]
  // attr [placeholder.shared.wmma.matrix_b] storage_scope = "wmma.matrix_b"
  allocate placeholder.shared.wmma.matrix_b[int4 * 32768]
  for (ax0.inner.ax1.fused.inner, 0, 2) {
    // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 2
    // attr [iter_var(blockIdx.y, , blockIdx.y)] thread_extent = 16
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    unrolled (n.c.init, 0, 2) {
      unrolled (o.c.init, 0, 16) {
        tvm_fill_fragment(Conv.wmma.accumulator, 8, 8, 32, ((n.c.init*16) + o.c.init), 0f)
      }
    }
    for (ic.outer, 0, 4) {
      unrolled (ax2.inner.inner, 0, 2) {
        unrolled (ax3, 0, 8) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          unrolled (ax4.ax5.fused.inner.outer, 0, 8) {
            if ((((blockIdx.z*2) + ax0.inner.ax1.fused.inner) < 49)) {
              compute.shared[((((threadIdx.y*512) + (ax2.inner.inner*256)) + (ax3*32)) + threadIdx.x)] = placeholder[(((((((((floordiv(((blockIdx.z*2) + ax0.inner.ax1.fused.inner), 7)*229376) + (floormod(((blockIdx.z*2) + ax0.inner.ax1.fused.inner), 7)*16384)) + (blockIdx.x*4096)) + (threadIdx.y*2048)) + (ax2.inner.inner*1024)) + (floordiv(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)*128)) + (ic.outer*32)) + (ax3*4)) + (floormod(((threadIdx.x*8) + ax4.ax5.fused.inner.outer), 32)/8))]
            }
          }
        }
      }
      unrolled (ax2, 0, 2) {
        unrolled (ax3, 0, 8) {
          if ((((blockIdx.z*2) + ax0.inner.ax1.fused.inner) < 49)) {
            tvm_load_matrix_sync(compute.shared.wmma.matrix_a, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), compute.shared, (((threadIdx.y*4096) + (ax2*2048)) + (ax3*256)), 256, 1), 32, "row_major")
          }
        }
      }
      // attr [placeholder.shared] double_buffer_scope = 1
      unrolled (ax2, 0, 16) {
        unrolled (ax3.inner.inner, 0, 4) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          placeholder.shared[((((ax2*256) + (threadIdx.y*128)) + (ax3.inner.inner*32)) + threadIdx.x)] = placeholder[((((((blockIdx.y*16384) + (ax2*1024)) + (ic.outer*256)) + (threadIdx.y*128)) + (ax3.inner.inner*32)) + threadIdx.x)]
        }
      }
      unrolled (ax2, 0, 16) {
        unrolled (ax3, 0, 8) {
          tvm_load_matrix_sync(placeholder.shared.wmma.matrix_b, 8, 8, 32, ((ax2*8) + ax3), tvm_access_ptr(type_annotation(), placeholder.shared, ((ax2*2048) + (ax3*256)), 256, 1), 32, "col_major")
        }
      }
      unrolled (ic.inner, 0, 8) {
        unrolled (n.c, 0, 2) {
          unrolled (o.c, 0, 16) {
            if ((((blockIdx.z*2) + ax0.inner.ax1.fused.inner) < 49)) {
              tvm_mma_sync(Conv.wmma.accumulator, ((n.c*16) + o.c), compute.shared.wmma.matrix_a, ((n.c*8) + ic.inner), placeholder.shared.wmma.matrix_b, ((o.c*8) + ic.inner), Conv.wmma.accumulator, ((n.c*16) + o.c))
            }
          }
        }
      }
    }
    unrolled (n.inner, 0, 2) {
      unrolled (o.inner, 0, 16) {
        if ((((blockIdx.z*2) + ax0.inner.ax1.fused.inner) < 49)) {
          tvm_store_matrix_sync(Conv.wmma.accumulator, 8, 8, 32, ((n.inner*16) + o.inner), tvm_access_ptr(type_annotation(), placeholder.shared, (((threadIdx.y*2048) + (n.inner*1024)) + (o.inner*64)), 64, 2), 8, "row_major")
        }
      }
    }
    // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 2
    // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1
    unrolled (ax2.outer.inner, 0, 2) {
      unrolled (ax3.outer.inner, 0, 16) {
        unrolled (ax2.inner.ax3.inner.fused.outer, 0, 2) {
          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 32
          if ((((blockIdx.z*2) + ax0.inner.ax1.fused.inner) < 49)) {
            T_cast[((((((((((blockIdx.z*262144) + (ax0.inner.ax1.fused.inner*131072)) + (blockIdx.x*65536)) + (threadIdx.y*32768)) + (ax2.outer.inner*16384)) + (ax2.inner.ax3.inner.fused.outer*8192)) + (floordiv(threadIdx.x, 8)*2048)) + (blockIdx.y*128)) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))] = (placeholder.shared[(((((threadIdx.y*2048) + (ax2.outer.inner*1024)) + (ax3.outer.inner*64)) + (ax2.inner.ax3.inner.fused.outer*32)) + threadIdx.x)] + placeholder[(((blockIdx.y*128) + (ax3.outer.inner*8)) + floormod(threadIdx.x, 8))])
          }
        }
      }
    }
  }
}
